<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Optimization | My New Hugo Site</title>
<meta name="keywords" content="Math, Machine_Learning">
<meta name="description" content="Introduction
In Machine Learning, the core problem is that solving the parameter estimation (model fitting), we want to find the values for a set of variable $\theta\in\Theta$, that minimized the scalar loss function or cost function $\mathcal{L}(\theta) \rightarrow \mathbb{R}$. This is called a optimization problem.
$$
\theta^* \in \arg\min \mathcal{L}(\theta)
$$
We will assume that the parameter space is given by $\Theta \subseteq \mathbb{R}^D$, where $D$ is the number of variables being optimized over.">
<meta name="author" content="">
<link rel="canonical" href="https://nguyentuss.github.io/posts/optimization/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.6da9a63d25a9608bca2f7f907a030e887a7dd3c3f3918e4cc113129361414bda.css" integrity="sha256-bammPSWpYIvKL3&#43;QegMOiHp908PzkY5MwRMSk2FBS9o=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://nguyentuss.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://nguyentuss.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://nguyentuss.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://nguyentuss.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://nguyentuss.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://nguyentuss.github.io/posts/optimization/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          throwOnError : false
        });
    });
</script>


<meta property="og:url" content="https://nguyentuss.github.io/posts/optimization/">
  <meta property="og:site_name" content="My New Hugo Site">
  <meta property="og:title" content="Optimization">
  <meta property="og:description" content="Introduction In Machine Learning, the core problem is that solving the parameter estimation (model fitting), we want to find the values for a set of variable $\theta\in\Theta$, that minimized the scalar loss function or cost function $\mathcal{L}(\theta) \rightarrow \mathbb{R}$. This is called a optimization problem. $$ \theta^* \in \arg\min \mathcal{L}(\theta) $$ We will assume that the parameter space is given by $\Theta \subseteq \mathbb{R}^D$, where $D$ is the number of variables being optimized over.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-20T13:34:38+07:00">
    <meta property="article:modified_time" content="2025-04-20T13:34:38+07:00">
    <meta property="article:tag" content="Math">
    <meta property="article:tag" content="Machine_Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Optimization">
<meta name="twitter:description" content="Introduction
In Machine Learning, the core problem is that solving the parameter estimation (model fitting), we want to find the values for a set of variable $\theta\in\Theta$, that minimized the scalar loss function or cost function $\mathcal{L}(\theta) \rightarrow \mathbb{R}$. This is called a optimization problem.
$$
\theta^* \in \arg\min \mathcal{L}(\theta)
$$
We will assume that the parameter space is given by $\Theta \subseteq \mathbb{R}^D$, where $D$ is the number of variables being optimized over.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://nguyentuss.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Optimization",
      "item": "https://nguyentuss.github.io/posts/optimization/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Optimization",
  "name": "Optimization",
  "description": "Introduction In Machine Learning, the core problem is that solving the parameter estimation (model fitting), we want to find the values for a set of variable $\\theta\\in\\Theta$, that minimized the scalar loss function or cost function $\\mathcal{L}(\\theta) \\rightarrow \\mathbb{R}$. This is called a optimization problem. $$ \\theta^* \\in \\arg\\min \\mathcal{L}(\\theta) $$ We will assume that the parameter space is given by $\\Theta \\subseteq \\mathbb{R}^D$, where $D$ is the number of variables being optimized over.\n",
  "keywords": [
    "Math", "Machine_Learning"
  ],
  "articleBody": "Introduction In Machine Learning, the core problem is that solving the parameter estimation (model fitting), we want to find the values for a set of variable $\\theta\\in\\Theta$, that minimized the scalar loss function or cost function $\\mathcal{L}(\\theta) \\rightarrow \\mathbb{R}$. This is called a optimization problem. $$ \\theta^* \\in \\arg\\min \\mathcal{L}(\\theta) $$ We will assume that the parameter space is given by $\\Theta \\subseteq \\mathbb{R}^D$, where $D$ is the number of variables being optimized over.\nIf we want to maximize a score function $R(\\theta)$, we can minimize the loss function $\\mathcal{L}(\\theta)=-R(\\theta)$, we will use this term objective function to determine a function we want to minimize or maximize. An algorithm that can find an optimum of an objective function is often called a solver.\nLocal and Global Optimization A point satisfies the optimization problem is called a global optimum. Finding such a point is called global optimization. In general, finding global optimum is very hard to compute. In such cases we will find the local optimum.\nA point $x^$ is called a local minimum if: $$ \\exists , \\varepsilon \u003e 0 \\text{ such that } f(x^) \\leq f(x), \\quad \\forall x \\text{ with } |x - x^*| \u003c \\varepsilon. $$\nA point $x^$ is a local maximum if: $$ \\exists , \\varepsilon \u003e 0 \\text{ such that } f(x^) \\geq f(x), \\quad \\forall x \\text{ with } |x - x^*| \u003c \\varepsilon. $$\nOptimality conditions for local and global optimum For continuous, twice differentiable functions, we can precisely characterize the points which correspond to local minima. Let $g(\\theta) = \\nabla\\mathcal{L}(\\theta)$ be the gradient vector, and $H(\\theta)=\\nabla^2 \\mathcal{L}(\\theta)$ be the Hessian matrix. Let $g^{}=g({\\theta}^{})$ be the gradient of that point and $H^=H(\\theta^*)$ be the corresponding Hessian. We can show that the following\nNecessary condition: If $\\theta^$ is a local minimum, then $g^=0$ and $H^*$ must be positive semi-difinite Sufficient condition: If $g^=0$ and $H^$ is positive definite, then $\\theta^$ is a local minimum. To see why the first condition is necessary, suppose we were at a point $\\theta^$ at which the gradient is non-zero, we could decrease the function by following the negative gradient a small distance, this can make the gradient become zero, but would not be the optimal. Note that the stationary point could be local minimum, local maximum or saddle point, which is a point where some directions point downhill, and some uphill. More precisely, at a saddle point, the eigenvalues of the Hessian will be both positive and negative. However, if the Hessian at a point is positive semi-definite, then some directions may point uphill, while others are flat. Moreover, if the Hessian is strictly positive definite, then we are at the bottom of a “bowl”, and all directions point uphill, which is sufficient for this to be a minimum. Constrained and unconstrained optimization Lagrange multipliers Lagrange multipliers, also sometimes called undermined multipliers, are used to find the stationary points of a function of several variables subject to one or more constraints. Consider the problem of finding the maximum of a function $f(x_1,x_2)$ subject to a constraint relating $x_1$ and $x_2$, which we write in the form $$ g(x_1,x_2)=0 $$ One approach would be to solve the constraint equation and thus express $x_2$ as a function of $x_1$ in the form $x_2=h(x_1)$. This can then be substituted into $f(x_1,x_2)$ to give a function of $x_1$ alone of the form $f(x_1, h(x_1))$. The maximum with respect to $x_1$ could then be found by differentiation in the usual way, to give the stationary value $\\hat{x}_1$(are found where the gradient is zero), which the corresponding value of $x_2$, $\\hat x_2 = h(\\hat x_1)$.\nOne problem with this approach is that it may be difficult to find an analytic solution of the constraint equation that allow $x_2$ to be expressed as an explicit function of $x_1$. Also, this approach treats $x_1$ and $x_2$ differently and so spoils the natural symmetry between these variables, it means that $x_2$ will depend on $x_1$ and make the function asymmetry into the problem that wasn’t there originally. The symmetry in here means that the problem treats both variables equally, none of those to be more important than other. Breaking the symmetry can make the math messier, limit the generality of the solution\nA more elegant, and often simpler, approach is have the $\\lambda$ called a Lagrange multiplier. We shall motivate this technique from a geometrical perspective. Consider a D-dimensional variable $\\mathbf{x}$ with the components $x_1,…,x_D$. The constraint equation $g(\\mathbf{x})=0$ then represents a (D-1)-dimensional surface in x-space as indicated in this image\nWe first note that at any point on the constraint surface the gradient $\\nabla g(\\mathbf{x})$ of the constraint function will be orthogonal to the surface. To see this, consider a point $\\mathbf{x}$ that lies on the constraints surface, and consider a nearby point $\\mathbf{x} + \\epsilon$ that also lies on the surface. If we make a Taylor expansion around $\\mathbf{x}$, we have $$ g(\\mathbf{x}+\\epsilon) \\simeq g(\\mathbf{x})+\\epsilon^T \\nabla g(\\mathbf{x}) $$ Because both $\\mathbf{x}$ and $\\mathbf{x}+\\epsilon$ lie on the constraint surface, we have $g(\\mathbf{x})=g(\\mathbf{x}+\\epsilon)$ and hence $\\epsilon^T \\nabla g(\\mathbf{x}) \\simeq 0$. In the limit $||\\epsilon|| \\rightarrow 0$ we have $\\epsilon^T \\nabla g(\\mathbf{x}) = 0$, and because $\\epsilon$ is then parallel to the constraint surface $g(\\mathbf{x})=0$, we see that the vector $\\nabla g$ is normal to the surface.\nNext we seek a point $\\hat{x}$ on the constraint surface such that $f(\\mathbf{x})$ is maximized. Such a point must have the property that the vector $\\nabla f(\\mathbf{x})$ is also orthogonal to the constraint surface, as illustrated in the figure above, because otherwise, we could increase the value $f(\\mathbf{x})$ by moving a short distance along the constraint surface. Thus, $\\nabla f$ and $\\nabla g$ are parallel (or anti-parallel) vectors, and so there must exist a parameter $\\lambda$ such that\n$$ \\nabla f+\\lambda \\nabla g=0 $$\nwhere $\\lambda \\neq 0$ is known as a Lagrange multiplier. Note that $\\lambda$ can have either sign. At this point, the Lagrange function is defined by\n$$ L(\\mathbf{x}, \\lambda) \\equiv f(\\mathbf{x}) + \\lambda g(\\mathbf{x}) $$ The constrained stationary condition is obtained by setting $\\nabla_\\mathbf{x} L = 0$. The condition $\\partial L/ \\partial\\lambda=0$ leads to the constraint equation $g(\\mathbf{x})=0$.\nThus, to find the maximum of a function $f(\\mathbf{x})$ subject to the constraint $g(\\mathbf{x})=0$, we define the Lagrangian with respect to both $\\mathbf{x}$ and $\\lambda$. For a D-dimensional vector $\\mathbf{x}$, this give D+1 equations that determine both the stationary point $\\widehat x$ and the value of $\\lambda$. If we are only interested in $\\widehat x$, then we can eliminate $\\lambda$ from the stationary equations without needing to find its value.\n$$ \\left{ \\begin{aligned} -2x_1 + \\lambda \u0026= 0 \\ -2x_2 + \\lambda \u0026=0 \\ x_1 + x_2 - 1 \u0026= 0 \\end{aligned} \\right. $$\nWe can also consider the problem of maximum with inequality constraint of the form $g(\\mathbf{x})\\geq 0$\n",
  "wordCount" : "1132",
  "inLanguage": "en",
  "datePublished": "2025-04-20T13:34:38+07:00",
  "dateModified": "2025-04-20T13:34:38+07:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nguyentuss.github.io/posts/optimization/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "My New Hugo Site",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nguyentuss.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://nguyentuss.github.io/" accesskey="h" title="My New Hugo Site (Alt + H)">My New Hugo Site</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Optimization
    </h1>
    <div class="post-meta"><span title='2025-04-20 13:34:38 +0700 +07'>April 20, 2025</span>

</div>
  </header> 
  <div class="post-content"><h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>In <em>Machine Learning</em>, the core problem is that solving the parameter estimation (model fitting), we want to find the values for a set of variable $\theta\in\Theta$, that minimized the scalar <strong>loss function</strong> or <strong>cost function</strong> $\mathcal{L}(\theta) \rightarrow \mathbb{R}$. This is called a <strong>optimization problem</strong>.
$$
\theta^* \in \arg\min \mathcal{L}(\theta)
$$
We will assume that the <em>parameter space</em> is given by $\Theta \subseteq \mathbb{R}^D$, where $D$ is the number of variables being optimized over.</p>
<p>If we want to <em>maximize</em> a <strong>score function</strong> $R(\theta)$, we can minimize the loss function $\mathcal{L}(\theta)=-R(\theta)$, we will use this term <strong>objective function</strong> to determine a function we want to minimize or maximize. An algorithm that can find an optimum of an objective function is often called a <strong>solver</strong>.</p>
<h3 id="local-and-global-optimization">Local and Global Optimization<a hidden class="anchor" aria-hidden="true" href="#local-and-global-optimization">#</a></h3>
<p>A point satisfies the optimization problem is called a <strong>global optimum</strong>. Finding such a point is called <strong>global optimization</strong>.
In general, finding global optimum is very hard to compute. In such cases we will find the <strong>local optimum</strong>.</p>
<!-- raw HTML omitted -->
<ul>
<li>
<p>A point $x^<em>$ is called a <strong>local minimum</strong> if:
$$
\exists , \varepsilon &gt; 0 \text{ such that } f(x^</em>) \leq f(x), \quad \forall x \text{ with } |x - x^*| &lt; \varepsilon.
$$</p>
</li>
<li>
<p>A point $x^<em>$ is a <strong>local maximum</strong> if:
$$
\exists , \varepsilon &gt; 0 \text{ such that } f(x^</em>) \geq f(x), \quad \forall x \text{ with } |x - x^*| &lt; \varepsilon.
$$</p>
</li>
</ul>
<h3 id="optimality-conditions-for-local-and-global-optimum">Optimality conditions for local and global optimum<a hidden class="anchor" aria-hidden="true" href="#optimality-conditions-for-local-and-global-optimum">#</a></h3>
<p>For continuous, twice differentiable functions, we can precisely characterize the points which correspond to local minima. Let $g(\theta) = \nabla\mathcal{L}(\theta)$ be the <em>gradient vector</em>, and $H(\theta)=\nabla^2 \mathcal{L}(\theta)$ be the Hessian matrix. Let $g^{}=g({\theta}^{<em>})$ be the gradient of that point and $H^</em>=H(\theta^*)$ be the corresponding Hessian. We can show that the following</p>
<ul>
<li>Necessary condition: If $\theta^<em>$ is a local minimum, then $g^</em>=0$ and $H^*$ must be <a href="https://www.math.purdue.edu/~eremenko/dvi/lect4.9">positive semi-difinite</a></li>
<li>Sufficient condition: If $g^<em>=0$ and $H^</em>$ is positive definite, then $\theta^<em>$ is a local minimum.
To see why the first condition is necessary, suppose we were at a point $\theta^</em>$ at which the gradient is non-zero, we could decrease the function by following the negative gradient a small distance, this can make the gradient become zero, but would not be the optimal. Note that the <strong>stationary point</strong> could be local minimum, local maximum or saddle point, which is a point where some directions point downhill, and some uphill. More precisely, at a saddle point, the eigenvalues of the Hessian will be both positive and negative. However, if the Hessian at a point is positive semi-definite, then some directions may point uphill, while others are flat. Moreover, if the Hessian is strictly positive definite, then we are at the bottom of a “bowl”, and all directions point uphill, which is sufficient for this to be a minimum.</li>
</ul>
<!-- raw HTML omitted -->
<h3 id="constrained-and-unconstrained-optimization">Constrained and unconstrained optimization<a hidden class="anchor" aria-hidden="true" href="#constrained-and-unconstrained-optimization">#</a></h3>
<h2 id="lagrange-multipliers">Lagrange multipliers<a hidden class="anchor" aria-hidden="true" href="#lagrange-multipliers">#</a></h2>
<p>Lagrange multipliers, also sometimes called undermined multipliers, are used to find the stationary points of a function of several variables subject to one or more constraints.
Consider the problem of finding the maximum of a function $f(x_1,x_2)$ subject to a constraint relating $x_1$ and $x_2$, which we write in the form
$$
g(x_1,x_2)=0
$$
One approach would be to solve the constraint equation and thus express $x_2$ as a function of $x_1$ in the form $x_2=h(x_1)$. This can then be substituted into $f(x_1,x_2)$ to give a function of $x_1$ alone of the form $f(x_1, h(x_1))$. The maximum with respect to $x_1$ could then be found by differentiation in the usual way, to give the stationary value $\hat{x}_1$(are found where the gradient is zero), which the corresponding value of $x_2$, $\hat x_2 = h(\hat x_1)$.</p>
<p>One problem with this approach is that it may be difficult to find an analytic solution of the constraint equation that allow $x_2$ to be expressed as an explicit function of $x_1$. Also, this approach treats $x_1$ and $x_2$ differently and so spoils the natural symmetry between these variables, it means that $x_2$ will depend on $x_1$ and make the function asymmetry into the problem that wasn&rsquo;t there originally. The symmetry in here means that the problem treats both variables equally, none of those to be more important than other.  Breaking the symmetry can make the math messier, limit the generality of the solution</p>
<p>A more elegant, and often simpler, approach is have the $\lambda$ called a Lagrange multiplier. We shall motivate this technique from a geometrical perspective. Consider a <em>D</em>-dimensional variable $\mathbf{x}$ with the components $x_1,&hellip;,x_D$. The constraint equation $g(\mathbf{x})=0$ then represents a (D-1)-dimensional surface in x-space as indicated in this image</p>
<!-- raw HTML omitted -->
<p>We first note that at any point on the constraint surface the gradient $\nabla g(\mathbf{x})$ of the constraint function will be orthogonal to the surface. To see this, consider a point $\mathbf{x}$ that lies on the constraints surface, and consider a nearby point $\mathbf{x} + \epsilon$ that also lies on the surface. If we make a Taylor expansion around $\mathbf{x}$, we have
$$
g(\mathbf{x}+\epsilon) \simeq g(\mathbf{x})+\epsilon^T \nabla g(\mathbf{x})
$$
Because both $\mathbf{x}$ and $\mathbf{x}+\epsilon$ lie on the constraint surface, we have $g(\mathbf{x})=g(\mathbf{x}+\epsilon)$ and hence $\epsilon^T \nabla g(\mathbf{x}) \simeq 0$. In the limit $||\epsilon|| \rightarrow 0$ we have $\epsilon^T \nabla g(\mathbf{x}) = 0$, and because $\epsilon$ is then parallel to the constraint surface $g(\mathbf{x})=0$, we see that the vector $\nabla g$ is normal to the surface.</p>
<p>Next we seek a point $\hat{x}$ on the constraint surface such that $f(\mathbf{x})$ is maximized. Such a point must have the property that the vector $\nabla f(\mathbf{x})$ is also orthogonal to the constraint surface, as illustrated in the figure above, because otherwise, we could increase the value $f(\mathbf{x})$ by moving a short distance along the constraint surface. Thus, $\nabla f$ and $\nabla g$ are parallel (or anti-parallel) vectors, and so there must exist a parameter $\lambda$ such that</p>
<p>$$
\nabla f+\lambda \nabla g=0
$$</p>
<p>where $\lambda \neq 0$ is known as a <em>Lagrange multiplier</em>. Note that $\lambda$ can have either sign.
At this point, the <em>Lagrange function</em> is defined by</p>
<p>$$
L(\mathbf{x}, \lambda) \equiv f(\mathbf{x}) + \lambda g(\mathbf{x})
$$
The constrained stationary condition is obtained by setting $\nabla_\mathbf{x} L = 0$. The condition $\partial L/ \partial\lambda=0$ leads to the constraint equation $g(\mathbf{x})=0$.</p>
<p>Thus, to find the maximum of a function $f(\mathbf{x})$ subject to the constraint $g(\mathbf{x})=0$, we define the Lagrangian with respect to both $\mathbf{x}$ and $\lambda$. For a D-dimensional vector $\mathbf{x}$, this give D+1 equations that determine both the stationary point $\widehat x$ and the value of $\lambda$. If we are only interested in $\widehat x$, then we can eliminate $\lambda$ from the stationary equations without needing to find its value.</p>
<!-- raw HTML omitted -->
<p>$$
\left{
\begin{aligned}
-2x_1 + \lambda &amp;= 0 \
-2x_2 + \lambda &amp;=0 \
x_1 + x_2 - 1 &amp;= 0
\end{aligned}
\right.
$$</p>
<!-- raw HTML omitted -->
<p>We can also consider the problem of maximum with <em>inequality constraint</em> of the form $g(\mathbf{x})\geq 0$</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://nguyentuss.github.io/tags/math/">Math</a></li>
      <li><a href="https://nguyentuss.github.io/tags/machine_learning/">Machine_Learning</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://nguyentuss.github.io/">My New Hugo Site</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
